model:
  name: "Transformer"
  type: "transformer"
  parameters:
    num_layers: 6
    d_model: 512
    num_heads: 8
    dff: 2048
    dropout_rate: 0.1
    activation: "relu"